{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagesDataset(Dataset):\n",
    "    \"\"\"Reads in an image, transforms pixel values, and serves\n",
    "    a dictionary containing the image id, image tensors, and label.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x_df: pd.DataFrame, y_df: pd.DataFrame | None = None, transforms=None):\n",
    "        self.data = x_df\n",
    "        self.label = y_df\n",
    "        if transforms is not None:\n",
    "            self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.data.iloc[index][\"filepath\"]).convert(\"RGB\")\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        image_id = self.data.index[index]\n",
    "        sample = {\"image_id\": image_id, \"image\": image}\n",
    "\n",
    "        if self.label is not None:\n",
    "            label = torch.tensor(self.label.iloc[index].values, dtype=torch.float)\n",
    "            sample |= {\"label\": label}\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training Data CSV:\n",
    "import pathlib\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def load_training_data(features_csv: str, labels_csv: str, images_dir: str,\n",
    "                       ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    features = pd.read_csv(features_csv, index_col=\"id\")\n",
    "    features['filepath'] = features['filepath'].apply(lambda path: pathlib.Path(images_dir) / str(path))\n",
    "    train_labels = pd.read_csv(labels_csv, index_col=\"id\")\n",
    "\n",
    "    y = train_labels\n",
    "    x = features.loc[y.index].filepath.to_frame()\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "x, y = load_training_data(features_csv, labels_csv, images_dir)\n",
    "x_train, x_eval, y_train, y_eval = train_test_split(x, y, stratify=y, test_size=0.25, random_state=42)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
